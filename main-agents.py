import os
import uuid
import threading
from dotenv import load_dotenv
from langchain_teddynote import logging

# API í‚¤ ì •ë³´ ë¡œë“œ
load_dotenv()

# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.
logging.langsmith("Agents-Only-Test")

openai_api_key = os.getenv('OPENAI_API_KEY')

##################################################################################
############################ tools: Tavily Searchs  ####################################
##################################################################################
from langchain_community.tools.tavily_search import TavilySearchResults
search = TavilySearchResults(k=6)

##################################################################################
############################ tools: Retriever ####################################
##################################################################################

from langchain_openai import OpenAIEmbeddings
import chromadb
from langchain_community.vectorstores import Chroma

client = chromadb.PersistentClient('chroma/')
embedding = OpenAIEmbeddings(model='text-embedding-3-large')  
vectorstore = Chroma(client=client, collection_name="49_files_openai_3072", embedding_function=embedding)

retriever = vectorstore.as_retriever(k=3)

from langchain.tools.retriever import create_retriever_tool
from langchain_core.prompts import PromptTemplate

# ë¬¸ì„œì˜ ë‚´ìš©ì„ í‘œì‹œí•˜ëŠ” í…œí”Œë¦¿ì„ ì •ì˜í•©ë‹ˆë‹¤.
document_prompt = PromptTemplate.from_template(
    "<document><content>{page_content}</content><source>{source}</source></document>"
)

# retriever ë¥¼ ë„êµ¬ë¡œ ì •ì˜í•©ë‹ˆë‹¤.
retriever_tool = create_retriever_tool(
    retriever,
    name="pdf_search",
    description="use this tool to search for information about Korean Address in the PDF file",
    document_prompt=document_prompt,
)

##################################################################################
############################ tools: Dall-E  ######################################
##################################################################################

from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper
from langchain.tools import tool

# DallE API Wrapperë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
dalle = DallEAPIWrapper(model="dall-e-3", size="1024x1024", quality="standard", n=1)


# DallE API Wrapperë¥¼ ë„êµ¬ë¡œ ì •ì˜í•©ë‹ˆë‹¤.
@tool
def dalle_tool(query):
    """use this tool to generate image from text"""
    return dalle.run(query)

##################################################################################
############################ tools: advanced assistant  ##########################
##################################################################################

from openai import OpenAI

@tool
def advanced_assistant(input, retrieved_data):
    """ ê³ ê¸‰ ê¸°ëŠ¥(ì˜ˆ: ê¸´ ë¬¸ì„œ ìƒì„±, ì¶”ë¡ ì´ í•„ìš”í•œ ë‹µë³€ ë“±)ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ """
    client = OpenAI()
 
    response = client.chat.completions.create(
        model="o3",
        messages=[
            { "role": "developer", "content": "You are a helpful assistant." },
            {
                "role": "user", 
                "content": input
            }
        ]
    )
    
    result = response.choices[0].message.content
    return result

##################################################################################
############################ tool binders  #######################################
##################################################################################

tools = [
    retriever_tool,
    search,
    dalle_tool,
    advanced_assistant
]

##################################################################################
############################ Agents  #############################################
##################################################################################

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_openai import ChatOpenAI

# ğŸ”§ ìŠ¤ë ˆë“œ ì•ˆì „í•œ ì €ì¥ì†Œ ì¶”ê°€
class ThreadSafeStore:
    def __init__(self):
        self._store = {}
        self._lock = threading.RLock()
    
    def get_session_history(self, session_id: str):
        with self._lock:
            if session_id not in self._store:
                self._store[session_id] = ChatMessageHistory()
                print(f"ğŸ†• ìƒˆë¡œìš´ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ìƒì„±: {session_id[:8]}...")
            return self._store[session_id]
    
    def clear_session(self, session_id: str = None):
        with self._lock:
            if session_id:
                if session_id in self._store:
                    message_count = len(self._store[session_id].messages)
                    del self._store[session_id]
                    return message_count
                return 0
            else:
                total_sessions = len(self._store)
                total_messages = sum(len(history.messages) for history in self._store.values())
                self._store.clear()
                return total_sessions, total_messages

# ì „ì—­ ìŠ¤ë ˆë“œ ì•ˆì „ ì €ì¥ì†Œ
thread_safe_store = ThreadSafeStore()

# session_id ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_session_history(session_id):
    return thread_safe_store.get_session_history(session_id)

# ìƒˆë¡œìš´ ì„¸ì…˜ ID ìƒì„± í•¨ìˆ˜
def generate_session_id():
    return str(uuid.uuid4())

# í”„ë¡¬í”„íŠ¸ ìƒì„±
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant used Korean ONLY. "
            "You are a professional researcher about Korean Address (e.g. ë„ë¡œëª…ì£¼ì†Œ, ì§€ë²ˆì£¼ì†Œ, í–‰ì •êµ¬ì—­, ê¸°íƒ€ 'ì£¼ì†Œ'ì™€ ê´€ë ¨ëœ ì‚°ì—…ê³¼ ê¸°ìˆ  ë“±). You can use the pdf_search tool to search for information about Korean Address in the PDF file. "
            "If you use pdf_search tool, you must state Cites from the reference on the bottom of your answer. "
            "If the information from pdf_search tool is insufficient, you can find further or recent information by using search tool. "
            "If you use search tool, you can add href link. "
            "You can use image generation tool to generate image from text. "
            "You can use advanced_assistant to write long report or reasoning tasks."
        ),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)

# LLM ìƒì„±
llm = ChatOpenAI(model="gpt-4.1")

# Agent ìƒì„±
agent = create_tool_calling_agent(llm, tools, prompt)

# AgentExecutor ìƒì„±
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=False,
    handle_parsing_errors=True,
)

# ì±„íŒ… ë©”ì‹œì§€ ê¸°ë¡ì´ ì¶”ê°€ëœ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
agent_with_chat_history = RunnableWithMessageHistory(
    agent_executor,
    get_session_history,
    input_messages_key="input",
    history_messages_key="chat_history",
)

##############################################################################################################
################################################Chat Interface################################################
##############################################################################################################

from fastapi import FastAPI, Request, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse, FileResponse
from pydantic import BaseModel
import json
import asyncio
from typing import AsyncGenerator
from langchain_teddynote.messages import AgentStreamParser

# ê° ë‹¨ê³„ë³„ ì¶œë ¥ì„ ìœ„í•œ íŒŒì„œ ìƒì„±
agent_stream_parser = AgentStreamParser()

app = FastAPI(title="Juso Chatbot API")

from pydantic_settings import BaseSettings
from functools import lru_cache
import os

class Settings(BaseSettings):
    OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")
    ALLOWED_ORIGINS: list = [
        "http://hike.cau.ac.kr",
        "http://localhost:3000",
        "http://localhost:3001"
    ]

@lru_cache()
def get_settings():
    return Settings() 

settings = get_settings()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class MessageRequest(BaseModel):
    message: str
    session_id: str = None  # ğŸ”§ session_id í•„ë“œ ì¶”ê°€

class FeedbackRequest(BaseModel):
    score: float
    run_id: str

async def generate_stream(questions: str) -> AsyncGenerator[str, None]:
    try:
        result = agent_with_chat_history.stream(
            {
                "input": questions
            },
            config={"configurable": {"session_id": "abc123"}},
        )
        
        full_response = ""
        for step in result:
            parsed_step = agent_stream_parser.process_agent_steps(step)
            if parsed_step:
                if isinstance(parsed_step, dict):
                    if 'content' in parsed_step:
                        full_response += parsed_step['content']
                    elif 'answer' in parsed_step:
                        full_response += parsed_step['answer']
                    else:
                        full_response += str(parsed_step)
                else:
                    full_response += str(parsed_step)
        
        # ìµœì¢… ì‘ë‹µì„ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        response_data = {
            "answer": full_response,
            "run_id": "run_" + str(hash(questions))  # ê°„ë‹¨í•œ run_id ìƒì„±
        }
        yield f"data: {json.dumps(response_data, ensure_ascii=False)}\n\n"
    except Exception as e:
        error_response = {
            "answer": f"Error: {str(e)}",
            "run_id": "error"
        }
        yield f"data: {json.dumps(error_response, ensure_ascii=False)}\n\n"

@app.post("/api/")
async def stream_responses(request: Request):
    try:
        data = await request.json()
        message = data.get('message')
        client_session_id = data.get('session_id')  # ğŸ”§ session_id ë°›ê¸°
        
        if not message:
            raise HTTPException(status_code=400, detail="Message is required")

        # ğŸ”§ ì„¸ì…˜ ID ì²˜ë¦¬
        if not client_session_id:
            client_session_id = generate_session_id()

        # ğŸ”§ ì„¸ì…˜ IDë¥¼ ì‚¬ìš©í•˜ì—¬ agent í˜¸ì¶œ
        result = agent_with_chat_history.invoke(
            {
                "input": message
            },
            config={"configurable": {"session_id": client_session_id}},
        )
        
        # ì‘ë‹µ ì²˜ë¦¬
        if isinstance(result, dict) and 'output' in result:
            response_data = {
                "answer": result['output'],
                "session_id": client_session_id,  # ğŸ”§ session_id ì‘ë‹µì— í¬í•¨
                "run_id": f"run_{hash(message)}"
            }
        else:
            response_data = {
                "answer": str(result),
                "session_id": client_session_id,  # ğŸ”§ session_id ì‘ë‹µì— í¬í•¨
                "run_id": f"run_{hash(message)}"
            }

        return JSONResponse(content=response_data)

    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.post("/api/reset")
async def reset_store(request: Request):
    try:
        data = await request.json()
        session_id_to_reset = data.get('session_id')  # ğŸ”§ íŠ¹ì • ì„¸ì…˜ ID ë°›ê¸°
        
        if session_id_to_reset:
            # ğŸ”§ íŠ¹ì • ì„¸ì…˜ë§Œ ì´ˆê¸°í™”
            message_count = thread_safe_store.clear_session(session_id_to_reset)
            new_session_id = generate_session_id()
            
            return {
                "status": "Session reset successfully",
                "session_id": new_session_id,
                "cleared_messages": message_count
            }
        else:
            # ğŸ”§ ëª¨ë“  ì„¸ì…˜ ì´ˆê¸°í™”
            total_sessions, total_messages = thread_safe_store.clear_session()
            new_session_id = generate_session_id()
            
            return {
                "status": "All sessions reset successfully", 
                "session_id": new_session_id,
                "cleared_sessions": total_sessions,
                "cleared_messages": total_messages
            }
    except Exception as e:
        # ğŸ”§ ì˜¤ë¥˜ ë°œìƒì‹œì—ë„ ìƒˆ ì„¸ì…˜ ID ë°˜í™˜
        new_session_id = generate_session_id()
        return {
            "status": "Sessions reset due to error",
            "session_id": new_session_id,
            "error": str(e)
        }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main_agents:app", host="0.0.0.0", port=8000, reload=True)